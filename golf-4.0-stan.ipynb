{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pystan\n",
    "import util\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sqlTxt = '''\n",
    "select player_id from stats_view where year = 2016 limit 50;\n",
    "'''\n",
    "player_ids = util.np_from_sql(sqlTxt);\n",
    "\n",
    "sqlTxt = '''\n",
    "select permanent_tournament_id, (b_offset).mean as offset,\n",
    "       (b_tee).mean as tee, (b_approach).mean as approach, \n",
    "       (b_around).mean as around, (b_putting).mean \n",
    "       from stan_sg_tournaments \n",
    "       where year = 2016 \n",
    "       and tag like 'sg-200';\n",
    "'''\n",
    "tournaments = util.pd_from_sql(sqlTxt).set_index(['permanent_tournament_id']).T.to_dict('list')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "sqlTxt = '''\n",
    "select name, permanent_tournament_id, round, scores.sg_tee as tee, scores.sg_approach as approach, \n",
    "       scores.sg_around as around, scores.sg_putting as putting from scores, players \n",
    "    where year = %s \n",
    "      and player_id = %s \n",
    "      and scores.player_id = players.player_id\n",
    "      and scores.sg_putting is not null\n",
    "      order by date;\n",
    "'''\n",
    "players_df = util.pd_from_sql(sqlTxt, [year, p_id])\n",
    "y = [players_df[sg].as_matrix() for sg in['tee', 'approach', 'around', 'tee'] ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pystan:COMPILING THE C++ CODE FOR MODEL anon_model_5ba58b23c8ed993b96402931dd3cdf47 NOW.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference for Stan model: anon_model_5ba58b23c8ed993b96402931dd3cdf47.\n",
      "4 chains, each with iter=1000; warmup=500; thin=1; \n",
      "post-warmup draws per chain=500, total post-warmup draws=2000.\n",
      "\n",
      "                   mean se_mean     sd   2.5%    25%    50%    75%  97.5%  n_eff   Rhat\n",
      "alpha[0,0]         0.36  4.7e-3   0.21  -0.05   0.22   0.35   0.49   0.79 2000.0    1.0\n",
      "alpha[1,0]         0.02  8.0e-3   0.36  -0.67  -0.22   0.02   0.26   0.74 2000.0    1.0\n",
      "alpha[2,0]         0.66  4.3e-3   0.19   0.29   0.54   0.67   0.79   1.06 2000.0    1.0\n",
      "alpha[3,0]         0.34  4.7e-3   0.21  -0.08    0.2   0.34   0.48   0.76 2000.0    1.0\n",
      "alpha[0,1]         0.38  4.5e-3    0.2  -0.03   0.25   0.39   0.52   0.76 2000.0    1.0\n",
      "alpha[1,1]         0.38  7.9e-3   0.35  -0.33   0.14   0.39   0.62   1.07 2000.0    1.0\n",
      "alpha[2,1]        -0.02  3.7e-3   0.17  -0.35  -0.13  -0.02   0.08    0.3 2000.0    1.0\n",
      "alpha[3,1]         0.38  4.5e-3    0.2-7.3e-3   0.25   0.38   0.51   0.77 2000.0    1.0\n",
      "beta[0]            0.27  3.0e-3   0.13 5.8e-3   0.19   0.28   0.36   0.52 2000.0    1.0\n",
      "beta[1]            0.01  3.0e-3   0.14  -0.25  -0.08   0.01   0.11   0.27 2000.0    1.0\n",
      "beta[2]            0.08  3.1e-3   0.14  -0.19-7.8e-3   0.08   0.18   0.36 2000.0    1.0\n",
      "beta[3]            0.28  2.9e-3   0.13   0.03   0.19   0.28   0.37   0.54 2000.0    1.0\n",
      "sigma[0]           1.02  2.3e-3    0.1   0.85   0.95   1.01   1.09   1.26 2000.0    1.0\n",
      "sigma[1]           1.85  4.1e-3   0.18   1.54   1.73   1.84   1.96   2.26 2000.0    1.0\n",
      "sigma[2]           0.89  2.1e-3   0.09   0.73   0.83   0.88   0.95    1.1 2000.0    1.0\n",
      "sigma[3]           1.02  2.3e-3    0.1   0.84   0.95   1.02   1.09   1.25 2000.0    1.0\n",
      "y_tilda[0,0]        0.4    0.02   1.03  -1.56   -0.3   0.38   1.09   2.53 2000.0    1.0\n",
      "y_tilda[1,0]        0.4    0.04   1.86  -3.11  -0.83   0.39   1.61   4.09 2000.0    1.0\n",
      "y_tilda[2,0]      -0.07    0.02   0.95  -1.98  -0.73  -0.08   0.58   1.78 2000.0    1.0\n",
      "y_tilda[3,0]       0.41    0.02   1.04  -1.62   -0.3   0.41   1.11   2.43 2000.0    1.0\n",
      "y_tilda[0,1]       0.48    0.02    1.1  -1.66  -0.25   0.48   1.21   2.69 2000.0    1.0\n",
      "y_tilda[1,1]       0.43    0.04   1.99  -3.42  -0.92   0.38   1.75   4.36 2000.0    1.0\n",
      "y_tilda[2,1]      -0.03    0.02   0.96  -1.94  -0.66-8.8e-3    0.6   1.88 2000.0    1.0\n",
      "y_tilda[3,1]       0.51    0.02   1.11  -1.68  -0.24    0.5   1.29   2.65 2000.0    1.0\n",
      "y_tilda[0,2]       0.51    0.02   1.09  -1.62  -0.24   0.54   1.21   2.65 2000.0    1.0\n",
      "y_tilda[1,2]        0.3    0.04   1.95  -3.57  -0.94   0.31   1.57   4.03 2000.0    1.0\n",
      "y_tilda[2,2]      -0.02    0.02   0.93  -1.83  -0.64  -0.04   0.56   1.88 2000.0    1.0\n",
      "y_tilda[3,2]       0.51    0.03   1.14  -1.78  -0.24   0.51   1.27   2.75 2000.0    1.0\n",
      "y_tilda[0,3]       0.52    0.02   1.11  -1.71  -0.22   0.49   1.25   2.78 2000.0    1.0\n",
      "y_tilda[1,3]       0.45    0.04   1.88  -3.38  -0.75   0.44   1.74   4.06 2000.0    1.0\n",
      "y_tilda[2,3]      -0.02    0.02   0.91  -1.85  -0.62  -0.02   0.58   1.73 2000.0    1.0\n",
      "y_tilda[3,3]       0.53    0.03   1.12  -1.57  -0.22   0.53   1.25   2.84 2000.0    1.0\n",
      "score_predict[0]  70.44    0.06   2.65  65.07  68.67  70.42  72.27  75.56 2000.0    1.0\n",
      "score_predict[1]  70.19    0.06   2.68  65.06  68.31  70.16  71.98  75.42 2000.0    1.0\n",
      "score_predict[2]  70.28    0.06   2.65  64.96  68.54   70.3  72.09  75.45 2000.0    1.0\n",
      "score_predict[3]   70.1    0.06   2.57  65.17  68.27   70.1  71.85  75.09 2000.0    1.0\n",
      "lp__             -151.5    0.15    4.3 -161.2 -154.1 -151.2 -148.4 -143.8  830.0    1.0\n",
      "\n",
      "Samples were drawn using NUTS at Sun Aug 13 21:59:33 2017.\n",
      "For each parameter, n_eff is a crude measure of effective sample size,\n",
      "and Rhat is the potential scale reduction factor on split chains (at \n",
      "convergence, Rhat=1).\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "\n",
    "code = '''\n",
    "data {\n",
    "    int<lower=2> N;\n",
    "    matrix[4,N] y;\n",
    "    int<lower=2> N_PRED;\n",
    "    real s_base;\n",
    "}\n",
    "parameters {\n",
    "    matrix[4,N_SEG] alpha;\n",
    "    vector[4] beta;\n",
    "    vector<lower=0>[4] sigma;\n",
    "    matrix[4,N_PRED] y_tilda;\n",
    "} \n",
    "model {\n",
    "    for (k in 1:4) {\n",
    "        for (n in 2:N) {\n",
    "            y[k][n] ~ normal(alpha[k][m]+ beta[k] * y[k][n-1], sigma[k]);\n",
    "        }\n",
    "    }\n",
    "    for (j in 1:4) {\n",
    "        y_tilda[j][1] ~ normal(alpha[j][N_SEG]+ beta[j] * y[j][N], sigma[j]);\n",
    "        for (i in 2:N_PRED) {\n",
    "            y_tilda[j][i] ~ normal(alpha[j][N_SEG] + beta[j]* y_tilda[j][i-1], sigma[j]);\n",
    "        }\n",
    "    }\n",
    "}\n",
    "generated quantities {\n",
    "      vector[N_PRED] score_predict;\n",
    "      for (l in 1:N_PRED) {\n",
    "        score_predict[l] = s_base - y_tilda[1][l] - y_tilda[2][l] - y_tilda[3][l] - y_tilda[4][l];\n",
    "    }\n",
    "}\n",
    "\n",
    "'''\n",
    "data = {\n",
    "    'N': len (y[0]),\n",
    "    'y': y,\n",
    "    'N_PRED' :1, \n",
    "    's_base' : 71.571\n",
    "}\n",
    "\n",
    "fit = pystan.stan(model_code=code, data=data, iter=1000, chains=4)\n",
    "# params = fs = fit.summary()['summary']\n",
    "print fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference for Stan model: anon_model_5ba58b23c8ed993b96402931dd3cdf47.\n",
      "4 chains, each with iter=1000; warmup=500; thin=1; \n",
      "post-warmup draws per chain=500, total post-warmup draws=2000.\n",
      "\n",
      "                   mean se_mean     sd   2.5%    25%    50%    75%  97.5%  n_eff   Rhat\n",
      "alpha[0,0]         0.81  5.3e-3   0.24   0.34   0.65    0.8   0.96   1.27 2000.0    1.0\n",
      "alpha[1,0]         0.78  7.5e-3   0.34   0.12   0.56   0.78    1.0   1.44 2000.0    1.0\n",
      "alpha[2,0]         0.43  4.0e-3   0.18   0.07   0.31   0.43   0.55   0.79 2000.0    1.0\n",
      "alpha[3,0]         0.81  5.1e-3   0.23   0.37   0.66    0.8   0.96   1.25 2000.0    1.0\n",
      "alpha[0,1]         0.49  4.6e-3    0.2   0.07   0.36   0.49   0.62   0.88 2000.0    1.0\n",
      "alpha[1,1]         0.37  7.0e-3   0.31  -0.22   0.15   0.37   0.59   1.01 2000.0    1.0\n",
      "alpha[2,1]         0.32  4.0e-3   0.18  -0.01    0.2   0.32   0.44   0.69 2000.0    1.0\n",
      "alpha[3,1]         0.49  4.7e-3   0.21   0.07   0.35   0.49   0.63   0.91 2000.0    1.0\n",
      "beta[0]            0.23  3.0e-3   0.12  -0.03   0.14   0.23   0.31   0.46 1727.0    1.0\n",
      "beta[1]            0.04  2.9e-3   0.13  -0.22  -0.05   0.03   0.12    0.3 2000.0    1.0\n",
      "beta[2]            0.15  2.8e-3   0.12   -0.1   0.07   0.16   0.24   0.39 2000.0    1.0\n",
      "beta[3]            0.23  3.0e-3   0.13  -0.02   0.14   0.23   0.31   0.47 1785.0    1.0\n",
      "sigma[0]           1.08  2.3e-3    0.1    0.9    1.0   1.07   1.14    1.3 2000.0    1.0\n",
      "sigma[1]            1.8  3.7e-3   0.16   1.52   1.69   1.79    1.9   2.18 2000.0    1.0\n",
      "sigma[2]           0.95  2.0e-3   0.09    0.8   0.89   0.94    1.0   1.14 2000.0    1.0\n",
      "sigma[3]           1.07  2.2e-3    0.1   0.91   1.01   1.07   1.13   1.29 2000.0    1.0\n",
      "y_tilda[0,0]       0.85    0.03   1.16  -1.56   0.11   0.86   1.58   3.19 2000.0    1.0\n",
      "y_tilda[1,0]       0.37    0.04   1.88  -3.32  -0.84   0.32   1.63   4.11 2000.0    1.0\n",
      "y_tilda[2,0]       0.22    0.02   0.98  -1.62  -0.45   0.23   0.89   2.13 2000.0    1.0\n",
      "y_tilda[3,0]       0.83    0.02   1.09  -1.27   0.08   0.83   1.59   2.98 2000.0    1.0\n",
      "y_tilda[0,1]       0.69    0.02   1.12  -1.51  -0.05   0.67   1.42   2.87 2000.0    1.0\n",
      "y_tilda[1,1]       0.41    0.04    1.8  -3.13  -0.84   0.42   1.67    3.9 2000.0    1.0\n",
      "y_tilda[2,1]       0.35    0.02   0.97   -1.6   -0.3   0.34   0.98   2.28 2000.0    1.0\n",
      "y_tilda[3,1]       0.67    0.03   1.14  -1.63  -0.07   0.65   1.42   2.95 2000.0    1.0\n",
      "y_tilda[0,2]       0.63    0.03   1.16  -1.72  -0.15   0.64   1.41   2.81 2000.0    1.0\n",
      "y_tilda[1,2]       0.46    0.04   1.94  -3.35  -0.84   0.45   1.74   4.32 2000.0    1.0\n",
      "y_tilda[2,2]       0.42    0.02   0.95  -1.49  -0.18   0.41   1.05   2.29 2000.0    1.0\n",
      "y_tilda[3,2]       0.64    0.02   1.09   -1.5  -0.07   0.64   1.36   2.71 2000.0    1.0\n",
      "y_tilda[0,3]       0.63    0.03   1.14  -1.64  -0.11   0.66   1.37   2.84 2000.0    1.0\n",
      "y_tilda[1,3]       0.37    0.04   1.82  -3.06   -0.9   0.36   1.67   3.84 2000.0    1.0\n",
      "y_tilda[2,3]       0.39    0.02   1.01  -1.67  -0.27   0.41   1.07   2.25 2000.0    1.0\n",
      "y_tilda[3,3]       0.65    0.03   1.15  -1.58  -0.13   0.67   1.45   2.85 2000.0    1.0\n",
      "score_predict[0]   69.3    0.06   2.65  64.17  67.53  69.25  71.05  74.53 2000.0    1.0\n",
      "score_predict[1]  69.45    0.06   2.49  64.48  67.77  69.44  71.08  74.43 2000.0    1.0\n",
      "score_predict[2]  69.42    0.06   2.64  64.18  67.68   69.4  71.26  74.58 2000.0    1.0\n",
      "score_predict[3]  69.53    0.06   2.71  64.42  67.69  69.52  71.38  74.89 2000.0    1.0\n",
      "lp__             -181.4    0.16   4.21 -190.5 -184.0 -180.9 -178.4 -174.1  707.0    1.0\n",
      "\n",
      "Samples were drawn using NUTS at Sat Aug 12 20:45:48 2017.\n",
      "For each parameter, n_eff is a crude measure of effective sample size,\n",
      "and Rhat is the potential scale reduction factor on split chains (at \n",
      "convergence, Rhat=1).\n"
     ]
    }
   ],
   "source": [
    "print fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pystan:COMPILING THE C++ CODE FOR MODEL anon_model_6abda944bb0b6acb21d3626f5be8dfef NOW.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference for Stan model: anon_model_6abda944bb0b6acb21d3626f5be8dfef.\n",
      "4 chains, each with iter=1000; warmup=500; thin=1; \n",
      "post-warmup draws per chain=500, total post-warmup draws=2000.\n",
      "\n",
      "           mean se_mean     sd   2.5%    25%    50%    75%  97.5%  n_eff   Rhat\n",
      "mu         0.61  9.2e-3   0.26   0.17   0.44    0.6   0.76   1.16  766.0    1.0\n",
      "phi[0]     0.33    0.02   0.34  -0.46   0.14   0.41   0.57   0.85  295.0   1.02\n",
      "phi[1]    -0.45    0.02   0.32   -0.9  -0.67  -0.51  -0.28   0.33  262.0   1.03\n",
      "theta[0]   -0.1    0.02    0.3  -0.59  -0.31  -0.16   0.06   0.62  300.0   1.02\n",
      "theta[1]    0.6    0.01   0.31  -0.18   0.46   0.68   0.84   0.97  450.0   1.02\n",
      "sigma      1.01  2.8e-3    0.1   0.84   0.94    1.0   1.07   1.22 1223.0    1.0\n",
      "y_tilda    0.62    0.03   1.08  -1.45  -0.09   0.63   1.31   2.82 1249.0    1.0\n",
      "lp__     -33.79    0.09   2.05 -38.48 -34.94  -33.4 -32.31 -30.78  523.0    1.0\n",
      "\n",
      "Samples were drawn using NUTS at Thu Aug 10 22:57:51 2017.\n",
      "For each parameter, n_eff is a crude measure of effective sample size,\n",
      "and Rhat is the potential scale reduction factor on split chains (at \n",
      "convergence, Rhat=1).\n"
     ]
    }
   ],
   "source": [
    "\n",
    "code = '''\n",
    "data {\n",
    "    int<lower=1> T;\n",
    "    real y[T];\n",
    "}\n",
    "parameters {\n",
    "    real mu;\n",
    "    vector<lower = -1, upper = 1>[2] phi;\n",
    "    vector<lower = -1, upper = 1>[2] theta;\n",
    "    real<lower=0> sigma;\n",
    "    real y_tilda;\n",
    "} \n",
    "model {\n",
    "    vector[T] nu;\n",
    "    vector[T] err;\n",
    "    nu[1] = mu + phi[1] * mu;\n",
    "    err[1] = y[1] - nu[1];\n",
    "    nu[2] = mu + phi[1]*y[1] + theta[1]*err[1];\n",
    "    err[2] = y[2] - nu[2];\n",
    "    for (t in 3:T) {\n",
    "        nu[t] = mu + phi[1] * y[t-1] + phi[2]*y[t-2] \n",
    "              + theta[1] * err[t-1] + theta[2] * err[t-2];\n",
    "        err[t] = y[t] - nu[t];\n",
    "    }\n",
    "    mu ~ normal(0, 10);\n",
    "    phi ~ normal(0, 2);\n",
    "    theta ~ normal(0, 2);\n",
    "    sigma ~ cauchy(0, 5);\n",
    "    err ~ normal(0, sigma);\n",
    "    y_tilda ~ normal(mu + y[T]*phi[1]+y[T-1]*phi[2] + theta[1]*err[T] + theta[2]*err[T-1], sigma);\n",
    "}\n",
    "\n",
    "'''\n",
    "y =  [ 2.352,  2.619,  3.292,  2.657,  0.739,  1.115,  0.148,  0.572,\n",
    "        0.859,  1.081,  1.104,  0.952, -1.324, -0.998,  1.124, -0.442,\n",
    "        0.824, -0.825, -2.64 , -0.563,  1.129,  1.047,  0.943,  0.781,\n",
    "       -0.933,  0.124,  0.341,  1.1  , -0.282,  1.173,  0.089,  1.544,\n",
    "        0.026, -0.855,  1.448,  0.426, -0.245,  1.346, -0.36 , -0.328,\n",
    "        0.482,  0.614,  0.572,  0.737, -0.097,  1.668, -0.012,  0.97 ,\n",
    "       -0.898,  0.159,  1.543, -0.297,  1.257,  0.761,  0.725,  0.629,\n",
    "        1.871,  0.061]\n",
    "data = {\n",
    "    'T': len (y),\n",
    "    'y': y\n",
    "}\n",
    "\n",
    "fit = pystan.stan(model_code=code, data=data, iter=1000, chains=4)\n",
    "# params = fs = fit.summary()['summary']\n",
    "print fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# \n",
    "\n",
    "code = '''\n",
    "data {\n",
    "    int<lower=1> N_SEG;\n",
    "    int<lower=2> N;\n",
    "    matrix[4,N] y;\n",
    "    int<lower=2> N_PRED;\n",
    "    real s_base;\n",
    "}\n",
    "parameters {\n",
    "    matrix[4,N_SEG] alpha;\n",
    "    vector[4] beta;\n",
    "    vector<lower=0>[4] sigma;\n",
    "    matrix[4,N_PRED] y_tilda;\n",
    "} \n",
    "model {\n",
    "    int m;\n",
    "    for (k in 1:4) {\n",
    "        for (n in 2:N) {\n",
    "            m = (n-1)*N_SEG/N + 1;\n",
    "            y[k][n] ~ normal(alpha[k][m]+ beta[k] * y[k][n-1], sigma[k]);\n",
    "        }\n",
    "    }\n",
    "    for (j in 1:4) {\n",
    "        y_tilda[j][1] ~ normal(alpha[j][N_SEG]+ beta[j] * y[j][N], sigma[j]);\n",
    "        for (i in 2:N_PRED) {\n",
    "            y_tilda[j][i] ~ normal(alpha[j][N_SEG] + beta[j]* y_tilda[j][i-1], sigma[j]);\n",
    "        }\n",
    "    }\n",
    "}\n",
    "generated quantities {\n",
    "      vector[N_PRED] score_predict;\n",
    "      for (l in 1:N_PRED) {\n",
    "        score_predict[l] = s_base - y_tilda[1][l] - y_tilda[2][l] - y_tilda[3][l] - y_tilda[4][l];\n",
    "    }\n",
    "}\n",
    "\n",
    "'''\n",
    "data = {\n",
    "    'N': len (y[0]),\n",
    "    'y': y,\n",
    "    'N_SEG' : 2,\n",
    "    'N_PRED' :4, \n",
    "    's_base' : 71.571\n",
    "}\n",
    "\n",
    "fit = pystan.stan(model_code=code, data=data, iter=1000, chains=4)\n",
    "# params = fs = fit.summary()['summary']\n",
    "print fit"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
