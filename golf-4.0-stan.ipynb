{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pystan\n",
    "import util\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>permanent_tournament_id</th>\n",
       "      <th>tee</th>\n",
       "      <th>approach</th>\n",
       "      <th>around</th>\n",
       "      <th>putting</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bubba Watson</td>\n",
       "      <td>16</td>\n",
       "      <td>3.716</td>\n",
       "      <td>0.727</td>\n",
       "      <td>1.569</td>\n",
       "      <td>-2.134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bubba Watson</td>\n",
       "      <td>16</td>\n",
       "      <td>4.233</td>\n",
       "      <td>2.264</td>\n",
       "      <td>0.480</td>\n",
       "      <td>-2.040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bubba Watson</td>\n",
       "      <td>16</td>\n",
       "      <td>3.721</td>\n",
       "      <td>-0.834</td>\n",
       "      <td>-0.391</td>\n",
       "      <td>-2.799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bubba Watson</td>\n",
       "      <td>16</td>\n",
       "      <td>4.268</td>\n",
       "      <td>1.240</td>\n",
       "      <td>0.470</td>\n",
       "      <td>0.017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bubba Watson</td>\n",
       "      <td>3</td>\n",
       "      <td>2.351</td>\n",
       "      <td>1.247</td>\n",
       "      <td>0.018</td>\n",
       "      <td>-1.456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Bubba Watson</td>\n",
       "      <td>3</td>\n",
       "      <td>0.752</td>\n",
       "      <td>2.393</td>\n",
       "      <td>0.297</td>\n",
       "      <td>-1.108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Bubba Watson</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.241</td>\n",
       "      <td>-0.067</td>\n",
       "      <td>-1.094</td>\n",
       "      <td>-0.045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Bubba Watson</td>\n",
       "      <td>3</td>\n",
       "      <td>2.269</td>\n",
       "      <td>1.435</td>\n",
       "      <td>1.076</td>\n",
       "      <td>0.726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Bubba Watson</td>\n",
       "      <td>5</td>\n",
       "      <td>0.647</td>\n",
       "      <td>-3.341</td>\n",
       "      <td>-1.716</td>\n",
       "      <td>0.801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Bubba Watson</td>\n",
       "      <td>7</td>\n",
       "      <td>0.910</td>\n",
       "      <td>2.265</td>\n",
       "      <td>-0.651</td>\n",
       "      <td>2.735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Bubba Watson</td>\n",
       "      <td>7</td>\n",
       "      <td>-2.073</td>\n",
       "      <td>3.692</td>\n",
       "      <td>2.101</td>\n",
       "      <td>-0.607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Bubba Watson</td>\n",
       "      <td>7</td>\n",
       "      <td>0.888</td>\n",
       "      <td>2.342</td>\n",
       "      <td>1.292</td>\n",
       "      <td>-0.293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Bubba Watson</td>\n",
       "      <td>7</td>\n",
       "      <td>1.240</td>\n",
       "      <td>2.676</td>\n",
       "      <td>-1.693</td>\n",
       "      <td>0.957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Bubba Watson</td>\n",
       "      <td>473</td>\n",
       "      <td>0.655</td>\n",
       "      <td>2.651</td>\n",
       "      <td>0.473</td>\n",
       "      <td>-0.635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Bubba Watson</td>\n",
       "      <td>473</td>\n",
       "      <td>2.276</td>\n",
       "      <td>1.662</td>\n",
       "      <td>-0.319</td>\n",
       "      <td>-0.692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Bubba Watson</td>\n",
       "      <td>473</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>0.055</td>\n",
       "      <td>1.691</td>\n",
       "      <td>-0.454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Bubba Watson</td>\n",
       "      <td>473</td>\n",
       "      <td>0.782</td>\n",
       "      <td>-0.430</td>\n",
       "      <td>0.711</td>\n",
       "      <td>3.456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Bubba Watson</td>\n",
       "      <td>470</td>\n",
       "      <td>2.612</td>\n",
       "      <td>-1.581</td>\n",
       "      <td>-0.312</td>\n",
       "      <td>-0.650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Bubba Watson</td>\n",
       "      <td>470</td>\n",
       "      <td>-0.478</td>\n",
       "      <td>-3.539</td>\n",
       "      <td>0.854</td>\n",
       "      <td>1.159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Bubba Watson</td>\n",
       "      <td>470</td>\n",
       "      <td>2.000</td>\n",
       "      <td>0.816</td>\n",
       "      <td>-1.447</td>\n",
       "      <td>-0.034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Bubba Watson</td>\n",
       "      <td>11</td>\n",
       "      <td>0.867</td>\n",
       "      <td>-1.057</td>\n",
       "      <td>-0.673</td>\n",
       "      <td>2.967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Bubba Watson</td>\n",
       "      <td>11</td>\n",
       "      <td>1.262</td>\n",
       "      <td>-0.429</td>\n",
       "      <td>0.452</td>\n",
       "      <td>-1.094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Bubba Watson</td>\n",
       "      <td>11</td>\n",
       "      <td>0.629</td>\n",
       "      <td>0.952</td>\n",
       "      <td>-1.325</td>\n",
       "      <td>-2.926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Bubba Watson</td>\n",
       "      <td>11</td>\n",
       "      <td>2.003</td>\n",
       "      <td>-1.279</td>\n",
       "      <td>-2.211</td>\n",
       "      <td>-1.400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Bubba Watson</td>\n",
       "      <td>23</td>\n",
       "      <td>1.523</td>\n",
       "      <td>-1.198</td>\n",
       "      <td>-1.206</td>\n",
       "      <td>0.420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Bubba Watson</td>\n",
       "      <td>23</td>\n",
       "      <td>0.280</td>\n",
       "      <td>1.729</td>\n",
       "      <td>-1.866</td>\n",
       "      <td>1.326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Bubba Watson</td>\n",
       "      <td>23</td>\n",
       "      <td>1.106</td>\n",
       "      <td>-1.906</td>\n",
       "      <td>-1.148</td>\n",
       "      <td>-0.516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Bubba Watson</td>\n",
       "      <td>23</td>\n",
       "      <td>1.744</td>\n",
       "      <td>-4.217</td>\n",
       "      <td>1.316</td>\n",
       "      <td>0.942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Bubba Watson</td>\n",
       "      <td>476</td>\n",
       "      <td>1.049</td>\n",
       "      <td>-2.109</td>\n",
       "      <td>1.623</td>\n",
       "      <td>-1.126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Bubba Watson</td>\n",
       "      <td>476</td>\n",
       "      <td>1.101</td>\n",
       "      <td>1.407</td>\n",
       "      <td>1.436</td>\n",
       "      <td>-1.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Bubba Watson</td>\n",
       "      <td>476</td>\n",
       "      <td>0.506</td>\n",
       "      <td>0.680</td>\n",
       "      <td>-0.673</td>\n",
       "      <td>0.818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Bubba Watson</td>\n",
       "      <td>476</td>\n",
       "      <td>2.329</td>\n",
       "      <td>-0.928</td>\n",
       "      <td>0.383</td>\n",
       "      <td>-0.298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Bubba Watson</td>\n",
       "      <td>33</td>\n",
       "      <td>1.535</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>0.063</td>\n",
       "      <td>-1.155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Bubba Watson</td>\n",
       "      <td>33</td>\n",
       "      <td>0.012</td>\n",
       "      <td>1.613</td>\n",
       "      <td>-0.026</td>\n",
       "      <td>0.452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Bubba Watson</td>\n",
       "      <td>33</td>\n",
       "      <td>2.130</td>\n",
       "      <td>-0.496</td>\n",
       "      <td>1.199</td>\n",
       "      <td>-1.494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Bubba Watson</td>\n",
       "      <td>33</td>\n",
       "      <td>0.197</td>\n",
       "      <td>0.140</td>\n",
       "      <td>-0.506</td>\n",
       "      <td>0.367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Bubba Watson</td>\n",
       "      <td>34</td>\n",
       "      <td>1.974</td>\n",
       "      <td>1.236</td>\n",
       "      <td>1.374</td>\n",
       "      <td>-1.840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Bubba Watson</td>\n",
       "      <td>34</td>\n",
       "      <td>-1.197</td>\n",
       "      <td>2.663</td>\n",
       "      <td>-1.051</td>\n",
       "      <td>-0.822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Bubba Watson</td>\n",
       "      <td>34</td>\n",
       "      <td>2.000</td>\n",
       "      <td>0.965</td>\n",
       "      <td>-2.635</td>\n",
       "      <td>1.376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Bubba Watson</td>\n",
       "      <td>34</td>\n",
       "      <td>1.308</td>\n",
       "      <td>-0.414</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Bubba Watson</td>\n",
       "      <td>27</td>\n",
       "      <td>-0.551</td>\n",
       "      <td>-0.089</td>\n",
       "      <td>0.707</td>\n",
       "      <td>0.550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Bubba Watson</td>\n",
       "      <td>27</td>\n",
       "      <td>-0.157</td>\n",
       "      <td>-0.627</td>\n",
       "      <td>0.844</td>\n",
       "      <td>-2.394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Bubba Watson</td>\n",
       "      <td>27</td>\n",
       "      <td>1.406</td>\n",
       "      <td>2.643</td>\n",
       "      <td>-0.239</td>\n",
       "      <td>-2.098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Bubba Watson</td>\n",
       "      <td>27</td>\n",
       "      <td>2.155</td>\n",
       "      <td>3.657</td>\n",
       "      <td>-0.633</td>\n",
       "      <td>0.445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Bubba Watson</td>\n",
       "      <td>505</td>\n",
       "      <td>0.481</td>\n",
       "      <td>0.480</td>\n",
       "      <td>1.620</td>\n",
       "      <td>-2.504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Bubba Watson</td>\n",
       "      <td>505</td>\n",
       "      <td>0.735</td>\n",
       "      <td>1.062</td>\n",
       "      <td>0.098</td>\n",
       "      <td>-2.815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Bubba Watson</td>\n",
       "      <td>28</td>\n",
       "      <td>0.893</td>\n",
       "      <td>-0.194</td>\n",
       "      <td>-0.306</td>\n",
       "      <td>0.902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Bubba Watson</td>\n",
       "      <td>28</td>\n",
       "      <td>1.805</td>\n",
       "      <td>2.622</td>\n",
       "      <td>0.716</td>\n",
       "      <td>0.111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Bubba Watson</td>\n",
       "      <td>28</td>\n",
       "      <td>1.675</td>\n",
       "      <td>1.005</td>\n",
       "      <td>-1.049</td>\n",
       "      <td>-1.916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Bubba Watson</td>\n",
       "      <td>28</td>\n",
       "      <td>1.678</td>\n",
       "      <td>2.078</td>\n",
       "      <td>-1.112</td>\n",
       "      <td>-1.140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Bubba Watson</td>\n",
       "      <td>60</td>\n",
       "      <td>1.145</td>\n",
       "      <td>-0.682</td>\n",
       "      <td>0.043</td>\n",
       "      <td>-1.601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Bubba Watson</td>\n",
       "      <td>60</td>\n",
       "      <td>2.550</td>\n",
       "      <td>-1.797</td>\n",
       "      <td>-0.114</td>\n",
       "      <td>-2.480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Bubba Watson</td>\n",
       "      <td>60</td>\n",
       "      <td>2.656</td>\n",
       "      <td>0.042</td>\n",
       "      <td>-0.187</td>\n",
       "      <td>2.778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Bubba Watson</td>\n",
       "      <td>60</td>\n",
       "      <td>2.045</td>\n",
       "      <td>0.494</td>\n",
       "      <td>0.479</td>\n",
       "      <td>1.085</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            name  permanent_tournament_id    tee  approach  around  putting\n",
       "0   Bubba Watson                       16  3.716     0.727   1.569   -2.134\n",
       "1   Bubba Watson                       16  4.233     2.264   0.480   -2.040\n",
       "2   Bubba Watson                       16  3.721    -0.834  -0.391   -2.799\n",
       "3   Bubba Watson                       16  4.268     1.240   0.470    0.017\n",
       "4   Bubba Watson                        3  2.351     1.247   0.018   -1.456\n",
       "5   Bubba Watson                        3  0.752     2.393   0.297   -1.108\n",
       "6   Bubba Watson                        3 -0.241    -0.067  -1.094   -0.045\n",
       "7   Bubba Watson                        3  2.269     1.435   1.076    0.726\n",
       "8   Bubba Watson                        5  0.647    -3.341  -1.716    0.801\n",
       "9   Bubba Watson                        7  0.910     2.265  -0.651    2.735\n",
       "10  Bubba Watson                        7 -2.073     3.692   2.101   -0.607\n",
       "11  Bubba Watson                        7  0.888     2.342   1.292   -0.293\n",
       "12  Bubba Watson                        7  1.240     2.676  -1.693    0.957\n",
       "13  Bubba Watson                      473  0.655     2.651   0.473   -0.635\n",
       "14  Bubba Watson                      473  2.276     1.662  -0.319   -0.692\n",
       "15  Bubba Watson                      473 -0.014     0.055   1.691   -0.454\n",
       "16  Bubba Watson                      473  0.782    -0.430   0.711    3.456\n",
       "17  Bubba Watson                      470  2.612    -1.581  -0.312   -0.650\n",
       "18  Bubba Watson                      470 -0.478    -3.539   0.854    1.159\n",
       "19  Bubba Watson                      470  2.000     0.816  -1.447   -0.034\n",
       "20  Bubba Watson                       11  0.867    -1.057  -0.673    2.967\n",
       "21  Bubba Watson                       11  1.262    -0.429   0.452   -1.094\n",
       "22  Bubba Watson                       11  0.629     0.952  -1.325   -2.926\n",
       "23  Bubba Watson                       11  2.003    -1.279  -2.211   -1.400\n",
       "24  Bubba Watson                       23  1.523    -1.198  -1.206    0.420\n",
       "25  Bubba Watson                       23  0.280     1.729  -1.866    1.326\n",
       "26  Bubba Watson                       23  1.106    -1.906  -1.148   -0.516\n",
       "27  Bubba Watson                       23  1.744    -4.217   1.316    0.942\n",
       "28  Bubba Watson                      476  1.049    -2.109   1.623   -1.126\n",
       "29  Bubba Watson                      476  1.101     1.407   1.436   -1.500\n",
       "30  Bubba Watson                      476  0.506     0.680  -0.673    0.818\n",
       "31  Bubba Watson                      476  2.329    -0.928   0.383   -0.298\n",
       "32  Bubba Watson                       33  1.535    -0.009   0.063   -1.155\n",
       "33  Bubba Watson                       33  0.012     1.613  -0.026    0.452\n",
       "34  Bubba Watson                       33  2.130    -0.496   1.199   -1.494\n",
       "35  Bubba Watson                       33  0.197     0.140  -0.506    0.367\n",
       "36  Bubba Watson                       34  1.974     1.236   1.374   -1.840\n",
       "37  Bubba Watson                       34 -1.197     2.663  -1.051   -0.822\n",
       "38  Bubba Watson                       34  2.000     0.965  -2.635    1.376\n",
       "39  Bubba Watson                       34  1.308    -0.414   0.077    0.654\n",
       "40  Bubba Watson                       27 -0.551    -0.089   0.707    0.550\n",
       "41  Bubba Watson                       27 -0.157    -0.627   0.844   -2.394\n",
       "42  Bubba Watson                       27  1.406     2.643  -0.239   -2.098\n",
       "43  Bubba Watson                       27  2.155     3.657  -0.633    0.445\n",
       "44  Bubba Watson                      505  0.481     0.480   1.620   -2.504\n",
       "45  Bubba Watson                      505  0.735     1.062   0.098   -2.815\n",
       "46  Bubba Watson                       28  0.893    -0.194  -0.306    0.902\n",
       "47  Bubba Watson                       28  1.805     2.622   0.716    0.111\n",
       "48  Bubba Watson                       28  1.675     1.005  -1.049   -1.916\n",
       "49  Bubba Watson                       28  1.678     2.078  -1.112   -1.140\n",
       "50  Bubba Watson                       60  1.145    -0.682   0.043   -1.601\n",
       "51  Bubba Watson                       60  2.550    -1.797  -0.114   -2.480\n",
       "52  Bubba Watson                       60  2.656     0.042  -0.187    2.778\n",
       "53  Bubba Watson                       60  2.045     0.494   0.479    1.085"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "player = 'Bubba Watson'\n",
    "year = 2016\n",
    "sqlTxt = '''\n",
    "select name, permanent_tournament_id, scores.sg_tee as tee, scores.sg_approach as approach, \n",
    "       scores.sg_around as around, scores.sg_putting as putting from scores, players \n",
    "    where year = %s \n",
    "      and name like %s \n",
    "      and scores.player_id = players.player_id\n",
    "      and scores.sg_putting is not null\n",
    "      order by date;\n",
    "'''\n",
    "players_df = util.pd_from_sql(sqlTxt, [year, player])\n",
    "y = [players_df[sg].as_matrix() for sg in['tee', 'approach', 'around', 'tee'] ]\n",
    "sqlTxt = '''\n",
    "select * from stan_sg_tournaments;\n",
    "'''\n",
    "tournaments_df = util.pd_from_sql(sqlTxt)\n",
    "players_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pystan:COMPILING THE C++ CODE FOR MODEL anon_model_5ba58b23c8ed993b96402931dd3cdf47 NOW.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference for Stan model: anon_model_5ba58b23c8ed993b96402931dd3cdf47.\n",
      "4 chains, each with iter=1000; warmup=500; thin=1; \n",
      "post-warmup draws per chain=500, total post-warmup draws=2000.\n",
      "\n",
      "                   mean se_mean     sd   2.5%    25%    50%    75%  97.5%  n_eff   Rhat\n",
      "alpha[0,0]         1.01  8.7e-3   0.32   0.41    0.8    1.0   1.23   1.66 1349.0    1.0\n",
      "alpha[1,0]         0.29  8.4e-3   0.35   -0.4   0.05   0.29   0.52   0.96 1747.0    1.0\n",
      "alpha[2,0]        -0.23  5.1e-3   0.23  -0.66  -0.38  -0.24  -0.08   0.21 2000.0    1.0\n",
      "alpha[3,0]         1.02  7.7e-3   0.31   0.42   0.81   1.01   1.22   1.63 1650.0    1.0\n",
      "alpha[0,1]         0.97  7.6e-3    0.3    0.4   0.77   0.98   1.17   1.55 1516.0    1.0\n",
      "alpha[1,1]         0.32  8.4e-3   0.34  -0.37   0.09   0.31   0.54   0.98 1647.0    1.0\n",
      "alpha[2,1]         0.13  4.9e-3   0.22   -0.3  -0.02   0.12   0.27   0.58 2000.0    1.0\n",
      "alpha[3,1]         0.96  7.0e-3   0.28   0.42   0.78   0.96   1.15   1.52 1658.0    1.0\n",
      "beta[0]            0.21  3.9e-3   0.14  -0.05   0.12   0.21   0.31   0.47 1243.0    1.0\n",
      "beta[1]            0.28  3.1e-3   0.14   0.01   0.19   0.28   0.37   0.56 2000.0    1.0\n",
      "beta[2]             0.1  3.2e-3   0.14  -0.19-3.3e-3   0.09   0.19   0.38 2000.0    1.0\n",
      "beta[3]            0.22  3.6e-3   0.13  -0.06   0.13   0.22   0.31   0.48 1387.0    1.0\n",
      "sigma[0]           1.23  2.9e-3   0.13   1.02   1.14   1.22   1.31   1.52 2000.0    1.0\n",
      "sigma[1]           1.78  4.2e-3   0.19   1.47   1.64   1.76    1.9    2.2 2000.0    1.0\n",
      "sigma[2]           1.12  2.6e-3   0.12   0.92   1.04   1.12    1.2   1.37 2000.0    1.0\n",
      "sigma[3]           1.23  2.8e-3   0.12   1.01   1.14   1.22    1.3   1.51 2000.0    1.0\n",
      "y_tilda[0,0]        1.4    0.03   1.33  -1.18   0.56   1.39   2.24   4.15 2000.0    1.0\n",
      "y_tilda[1,0]       0.46    0.04   1.85  -3.02  -0.81   0.44   1.66   4.34 2000.0    1.0\n",
      "y_tilda[2,0]       0.16    0.02   1.11  -1.95   -0.6   0.15    0.9   2.36 2000.0    1.0\n",
      "y_tilda[3,0]       1.44    0.03   1.29  -1.13   0.57   1.42   2.31   3.96 2000.0    1.0\n",
      "y_tilda[0,1]       1.28    0.03   1.35  -1.39   0.38   1.29   2.23   3.93 1584.0    1.0\n",
      "y_tilda[1,1]       0.48    0.06   1.98  -3.48  -0.75   0.49   1.74    4.4 1210.0    1.0\n",
      "y_tilda[2,1]       0.15    0.03   1.17  -2.29  -0.56   0.18   0.93   2.62 2000.0    1.0\n",
      "y_tilda[3,1]       1.28    0.03   1.34  -1.38   0.38   1.29   2.16   3.98 2000.0    1.0\n",
      "y_tilda[0,2]       1.23    0.03   1.39  -1.56   0.34   1.23   2.18   3.89 2000.0    1.0\n",
      "y_tilda[1,2]       0.53    0.05   1.96  -3.25  -0.84   0.55   1.85   4.36 1513.0    1.0\n",
      "y_tilda[2,2]       0.16    0.03   1.23  -2.26  -0.62   0.14   0.94   2.68 2000.0    1.0\n",
      "y_tilda[3,2]       1.22    0.03   1.29  -1.25   0.31   1.22   2.09   3.71 2000.0    1.0\n",
      "y_tilda[0,3]       1.22    0.03   1.34  -1.47   0.33   1.22    2.1   3.83 2000.0    1.0\n",
      "y_tilda[1,3]       0.47    0.05    2.0  -3.41  -0.87   0.45   1.88   4.33 1642.0    1.0\n",
      "y_tilda[2,3]       0.13    0.03    1.2  -2.21  -0.65   0.09   0.95   2.45 2000.0    1.0\n",
      "y_tilda[3,3]       1.25    0.03   1.33  -1.28   0.31   1.25   2.15   3.79 2000.0    1.0\n",
      "score_predict[0]   68.1    0.06    2.8  62.27  66.28  68.18   70.0  73.43 2000.0    1.0\n",
      "score_predict[1]  68.38    0.07   2.97   62.5   66.5  68.35   70.4  74.05 2000.0    1.0\n",
      "score_predict[2]  68.42    0.06    2.9  62.52  66.45  68.49  70.43  73.89 2000.0    1.0\n",
      "score_predict[3]   68.5    0.07   2.99  62.47  66.49  68.58  70.53  74.42 2000.0    1.0\n",
      "lp__             -172.8    0.15   4.45 -182.6 -175.5 -172.4 -169.6 -165.3  831.0   1.01\n",
      "\n",
      "Samples were drawn using NUTS at Sat Aug 12 20:47:25 2017.\n",
      "For each parameter, n_eff is a crude measure of effective sample size,\n",
      "and Rhat is the potential scale reduction factor on split chains (at \n",
      "convergence, Rhat=1).\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "\n",
    "code = '''\n",
    "data {\n",
    "    int<lower=1> N_SEG;\n",
    "    int<lower=2> N;\n",
    "    matrix[4,N] y;\n",
    "    int<lower=2> N_PRED;\n",
    "    real s_base;\n",
    "}\n",
    "parameters {\n",
    "    matrix[4,N_SEG] alpha;\n",
    "    vector[4] beta;\n",
    "    vector<lower=0>[4] sigma;\n",
    "    matrix[4,N_PRED] y_tilda;\n",
    "} \n",
    "model {\n",
    "    int m;\n",
    "    for (k in 1:4) {\n",
    "        for (n in 2:N) {\n",
    "            m = (n-1)*N_SEG/N + 1;\n",
    "            y[k][n] ~ normal(alpha[k][m]+ beta[k] * y[k][n-1], sigma[k]);\n",
    "        }\n",
    "    }\n",
    "    for (j in 1:4) {\n",
    "        y_tilda[j][1] ~ normal(alpha[j][N_SEG]+ beta[j] * y[j][N], sigma[j]);\n",
    "        for (i in 2:N_PRED) {\n",
    "            y_tilda[j][i] ~ normal(alpha[j][N_SEG] + beta[j]* y_tilda[j][i-1], sigma[j]);\n",
    "        }\n",
    "    }\n",
    "}\n",
    "generated quantities {\n",
    "      vector[N_PRED] score_predict;\n",
    "      for (l in 1:N_PRED) {\n",
    "        score_predict[l] = s_base - y_tilda[1][l] - y_tilda[2][l] - y_tilda[3][l] - y_tilda[4][l];\n",
    "    }\n",
    "}\n",
    "\n",
    "'''\n",
    "data = {\n",
    "    'N': len (y[0]),\n",
    "    'y': y,\n",
    "    'N_SEG' : 2,\n",
    "    'N_PRED' :4, \n",
    "    's_base' : 71.571\n",
    "}\n",
    "\n",
    "fit = pystan.stan(model_code=code, data=data, iter=1000, chains=4)\n",
    "# params = fs = fit.summary()['summary']\n",
    "print fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference for Stan model: anon_model_5ba58b23c8ed993b96402931dd3cdf47.\n",
      "4 chains, each with iter=1000; warmup=500; thin=1; \n",
      "post-warmup draws per chain=500, total post-warmup draws=2000.\n",
      "\n",
      "                   mean se_mean     sd   2.5%    25%    50%    75%  97.5%  n_eff   Rhat\n",
      "alpha[0,0]         0.81  5.3e-3   0.24   0.34   0.65    0.8   0.96   1.27 2000.0    1.0\n",
      "alpha[1,0]         0.78  7.5e-3   0.34   0.12   0.56   0.78    1.0   1.44 2000.0    1.0\n",
      "alpha[2,0]         0.43  4.0e-3   0.18   0.07   0.31   0.43   0.55   0.79 2000.0    1.0\n",
      "alpha[3,0]         0.81  5.1e-3   0.23   0.37   0.66    0.8   0.96   1.25 2000.0    1.0\n",
      "alpha[0,1]         0.49  4.6e-3    0.2   0.07   0.36   0.49   0.62   0.88 2000.0    1.0\n",
      "alpha[1,1]         0.37  7.0e-3   0.31  -0.22   0.15   0.37   0.59   1.01 2000.0    1.0\n",
      "alpha[2,1]         0.32  4.0e-3   0.18  -0.01    0.2   0.32   0.44   0.69 2000.0    1.0\n",
      "alpha[3,1]         0.49  4.7e-3   0.21   0.07   0.35   0.49   0.63   0.91 2000.0    1.0\n",
      "beta[0]            0.23  3.0e-3   0.12  -0.03   0.14   0.23   0.31   0.46 1727.0    1.0\n",
      "beta[1]            0.04  2.9e-3   0.13  -0.22  -0.05   0.03   0.12    0.3 2000.0    1.0\n",
      "beta[2]            0.15  2.8e-3   0.12   -0.1   0.07   0.16   0.24   0.39 2000.0    1.0\n",
      "beta[3]            0.23  3.0e-3   0.13  -0.02   0.14   0.23   0.31   0.47 1785.0    1.0\n",
      "sigma[0]           1.08  2.3e-3    0.1    0.9    1.0   1.07   1.14    1.3 2000.0    1.0\n",
      "sigma[1]            1.8  3.7e-3   0.16   1.52   1.69   1.79    1.9   2.18 2000.0    1.0\n",
      "sigma[2]           0.95  2.0e-3   0.09    0.8   0.89   0.94    1.0   1.14 2000.0    1.0\n",
      "sigma[3]           1.07  2.2e-3    0.1   0.91   1.01   1.07   1.13   1.29 2000.0    1.0\n",
      "y_tilda[0,0]       0.85    0.03   1.16  -1.56   0.11   0.86   1.58   3.19 2000.0    1.0\n",
      "y_tilda[1,0]       0.37    0.04   1.88  -3.32  -0.84   0.32   1.63   4.11 2000.0    1.0\n",
      "y_tilda[2,0]       0.22    0.02   0.98  -1.62  -0.45   0.23   0.89   2.13 2000.0    1.0\n",
      "y_tilda[3,0]       0.83    0.02   1.09  -1.27   0.08   0.83   1.59   2.98 2000.0    1.0\n",
      "y_tilda[0,1]       0.69    0.02   1.12  -1.51  -0.05   0.67   1.42   2.87 2000.0    1.0\n",
      "y_tilda[1,1]       0.41    0.04    1.8  -3.13  -0.84   0.42   1.67    3.9 2000.0    1.0\n",
      "y_tilda[2,1]       0.35    0.02   0.97   -1.6   -0.3   0.34   0.98   2.28 2000.0    1.0\n",
      "y_tilda[3,1]       0.67    0.03   1.14  -1.63  -0.07   0.65   1.42   2.95 2000.0    1.0\n",
      "y_tilda[0,2]       0.63    0.03   1.16  -1.72  -0.15   0.64   1.41   2.81 2000.0    1.0\n",
      "y_tilda[1,2]       0.46    0.04   1.94  -3.35  -0.84   0.45   1.74   4.32 2000.0    1.0\n",
      "y_tilda[2,2]       0.42    0.02   0.95  -1.49  -0.18   0.41   1.05   2.29 2000.0    1.0\n",
      "y_tilda[3,2]       0.64    0.02   1.09   -1.5  -0.07   0.64   1.36   2.71 2000.0    1.0\n",
      "y_tilda[0,3]       0.63    0.03   1.14  -1.64  -0.11   0.66   1.37   2.84 2000.0    1.0\n",
      "y_tilda[1,3]       0.37    0.04   1.82  -3.06   -0.9   0.36   1.67   3.84 2000.0    1.0\n",
      "y_tilda[2,3]       0.39    0.02   1.01  -1.67  -0.27   0.41   1.07   2.25 2000.0    1.0\n",
      "y_tilda[3,3]       0.65    0.03   1.15  -1.58  -0.13   0.67   1.45   2.85 2000.0    1.0\n",
      "score_predict[0]   69.3    0.06   2.65  64.17  67.53  69.25  71.05  74.53 2000.0    1.0\n",
      "score_predict[1]  69.45    0.06   2.49  64.48  67.77  69.44  71.08  74.43 2000.0    1.0\n",
      "score_predict[2]  69.42    0.06   2.64  64.18  67.68   69.4  71.26  74.58 2000.0    1.0\n",
      "score_predict[3]  69.53    0.06   2.71  64.42  67.69  69.52  71.38  74.89 2000.0    1.0\n",
      "lp__             -181.4    0.16   4.21 -190.5 -184.0 -180.9 -178.4 -174.1  707.0    1.0\n",
      "\n",
      "Samples were drawn using NUTS at Sat Aug 12 20:45:48 2017.\n",
      "For each parameter, n_eff is a crude measure of effective sample size,\n",
      "and Rhat is the potential scale reduction factor on split chains (at \n",
      "convergence, Rhat=1).\n"
     ]
    }
   ],
   "source": [
    "print fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "code = '''\n",
    "data {\n",
    "    int<lower=1> T;\n",
    "    real y[T];\n",
    "}\n",
    "parameters {\n",
    "    real mu;\n",
    "    vector<lower = -1, upper = 1>[2] phi;\n",
    "    vector<lower = -1, upper = 1>[2] theta;\n",
    "    real<lower=0> sigma;\n",
    "} \n",
    "model {\n",
    "    vector[T] nu;\n",
    "    vector[T] err;\n",
    "    nu[1] = mu + phi[1] * mu;\n",
    "    err[1] = y[1] - nu[1];\n",
    "    nu[2] = mu + phi[1]*y[1] + theta[1]*err[1];\n",
    "    err[2] = y[2] - nu[2];\n",
    "    for (t in 3:T) {\n",
    "        nu[t] = mu + phi[1] * y[t-1] + phi[2]*y[t-2] \n",
    "              + theta[1] * err[t-1] + theta[2] * err[t-2];\n",
    "        err[t] = y[t] - nu[t];\n",
    "    }\n",
    "    mu ~ normal(0, 10);\n",
    "    phi ~ normal(0, 2);\n",
    "    theta ~ normal(0, 2);\n",
    "    sigma ~ cauchy(0, 5);\n",
    "    err ~ normal(0, sigma);\n",
    "}\n",
    "'''\n",
    "y =  [ 0.596,  2.127,  3.093,  0.423, -1.508,  3.28 , -5.571,  2.623,\n",
    "        1.335, -1.234, -0.364,  0.081, -1.076, -0.791,  1.715,  1.266,\n",
    "        0.566, -1.333,  1.871,  2.429, -2.064, -0.336,  1.407,  2.787,\n",
    "        2.743, -3.073,  1.335,  1.163,  2.982,  4.317,  2.913,  0.432,\n",
    "       -3.238,  1.785,  2.766,  2.252,  1.024,  2.167, -0.334, -0.106,\n",
    "        1.959, -0.784,  0.387,  2.816, -0.762, -1.897,  1.99 , -0.965,\n",
    "        2.714,  1.237,  0.701,  3.814, -1.459,  1.021,  4.114,  0.038,\n",
    "       -1.391,  2.91 ]\n",
    "data = {\n",
    "    'T': len (y),\n",
    "    'y': y\n",
    "}\n",
    "\n",
    "fit = pystan.stan(model_code=code, data=data, iter=1000, chains=4)\n",
    "# params = fs = fit.summary()['summary']\n",
    "print fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pystan:COMPILING THE C++ CODE FOR MODEL anon_model_6abda944bb0b6acb21d3626f5be8dfef NOW.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference for Stan model: anon_model_6abda944bb0b6acb21d3626f5be8dfef.\n",
      "4 chains, each with iter=1000; warmup=500; thin=1; \n",
      "post-warmup draws per chain=500, total post-warmup draws=2000.\n",
      "\n",
      "           mean se_mean     sd   2.5%    25%    50%    75%  97.5%  n_eff   Rhat\n",
      "mu         0.61  9.2e-3   0.26   0.17   0.44    0.6   0.76   1.16  766.0    1.0\n",
      "phi[0]     0.33    0.02   0.34  -0.46   0.14   0.41   0.57   0.85  295.0   1.02\n",
      "phi[1]    -0.45    0.02   0.32   -0.9  -0.67  -0.51  -0.28   0.33  262.0   1.03\n",
      "theta[0]   -0.1    0.02    0.3  -0.59  -0.31  -0.16   0.06   0.62  300.0   1.02\n",
      "theta[1]    0.6    0.01   0.31  -0.18   0.46   0.68   0.84   0.97  450.0   1.02\n",
      "sigma      1.01  2.8e-3    0.1   0.84   0.94    1.0   1.07   1.22 1223.0    1.0\n",
      "y_tilda    0.62    0.03   1.08  -1.45  -0.09   0.63   1.31   2.82 1249.0    1.0\n",
      "lp__     -33.79    0.09   2.05 -38.48 -34.94  -33.4 -32.31 -30.78  523.0    1.0\n",
      "\n",
      "Samples were drawn using NUTS at Thu Aug 10 22:57:51 2017.\n",
      "For each parameter, n_eff is a crude measure of effective sample size,\n",
      "and Rhat is the potential scale reduction factor on split chains (at \n",
      "convergence, Rhat=1).\n"
     ]
    }
   ],
   "source": [
    "\n",
    "code = '''\n",
    "data {\n",
    "    int<lower=1> T;\n",
    "    real y[T];\n",
    "}\n",
    "parameters {\n",
    "    real mu;\n",
    "    vector<lower = -1, upper = 1>[2] phi;\n",
    "    vector<lower = -1, upper = 1>[2] theta;\n",
    "    real<lower=0> sigma;\n",
    "    real y_tilda;\n",
    "} \n",
    "model {\n",
    "    vector[T] nu;\n",
    "    vector[T] err;\n",
    "    nu[1] = mu + phi[1] * mu;\n",
    "    err[1] = y[1] - nu[1];\n",
    "    nu[2] = mu + phi[1]*y[1] + theta[1]*err[1];\n",
    "    err[2] = y[2] - nu[2];\n",
    "    for (t in 3:T) {\n",
    "        nu[t] = mu + phi[1] * y[t-1] + phi[2]*y[t-2] \n",
    "              + theta[1] * err[t-1] + theta[2] * err[t-2];\n",
    "        err[t] = y[t] - nu[t];\n",
    "    }\n",
    "    mu ~ normal(0, 10);\n",
    "    phi ~ normal(0, 2);\n",
    "    theta ~ normal(0, 2);\n",
    "    sigma ~ cauchy(0, 5);\n",
    "    err ~ normal(0, sigma);\n",
    "    y_tilda ~ normal(mu + y[T]*phi[1]+y[T-1]*phi[2] + theta[1]*err[T] + theta[2]*err[T-1], sigma);\n",
    "}\n",
    "\n",
    "'''\n",
    "y =  [ 2.352,  2.619,  3.292,  2.657,  0.739,  1.115,  0.148,  0.572,\n",
    "        0.859,  1.081,  1.104,  0.952, -1.324, -0.998,  1.124, -0.442,\n",
    "        0.824, -0.825, -2.64 , -0.563,  1.129,  1.047,  0.943,  0.781,\n",
    "       -0.933,  0.124,  0.341,  1.1  , -0.282,  1.173,  0.089,  1.544,\n",
    "        0.026, -0.855,  1.448,  0.426, -0.245,  1.346, -0.36 , -0.328,\n",
    "        0.482,  0.614,  0.572,  0.737, -0.097,  1.668, -0.012,  0.97 ,\n",
    "       -0.898,  0.159,  1.543, -0.297,  1.257,  0.761,  0.725,  0.629,\n",
    "        1.871,  0.061]\n",
    "data = {\n",
    "    'T': len (y),\n",
    "    'y': y\n",
    "}\n",
    "\n",
    "fit = pystan.stan(model_code=code, data=data, iter=1000, chains=4)\n",
    "# params = fs = fit.summary()['summary']\n",
    "print fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
